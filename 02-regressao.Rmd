# Regressão {#regressao}

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(GGally)
library(broom)
```


A técnica chamada de regressão é usada para predizer o valor de uma variável Y (chamada de variável resposta ou dependente) baseado em uma ou mais variáveis X (variável explanatória ou independente). Se a regressão utiliza apenas uma variável explanatória, é chamada de regressão simples. O objetivo da regressão é representar a relação entre as variáveis resposta e explanatória por meio de uma equação matemática linear do tipo:

$Y = \beta_1 + \beta_2X + \epsilon$

onde $\beta_1$ é a interceptação da reta com o eixo vertical e $\beta2$ o coeficiente de inclinação associado à variável explanatória. Tais elementos são chamados coeficientes da regressão. O termo $\epsilon$ representa o termo do erro, que é a parte de Y que a regressão é incapaz de explicar (por existir outras variáveis que explicariam Y mas que não foram incorporadas ao modelo).


Neste módulo, usaremos como exemplo o dataset do Kaggle de [Bicicletas compartilhadas em Washington D.C.](https://www.kaggle.com/marklvl/bike-sharing-dataset), nos Estados Unidos. Baixe o arquivo zip do Kaggle e leia o README para entender o que o dataset representa e suas variáveis significam. Vamos importar apenas 


```{r regressao-ch02, message = FALSE}
df <- readr::read_csv("https://raw.githubusercontent.com/sillasgonzaga/curso_series_temporais/master/data/Bike-Sharing-Dataset/day.csv")
# dando olhada nos dados
# glimpse(df)

```

Seguindo o que aprendemos a partir da leitura do README, vamos fazer algumas transformações de colunas antes de proceder com a modelagem:

```{r}
df_transf <- df %>% 
  # remover colunas irrelevantes
  select(-c(instant, workingday)) %>% 
  # renomear algumas colunas
  rename(
    estacao = season,
    total = cnt,
    year = yr, 
    month = mnth
  ) %>% 
  # mudar weekday, que começa a contar do zero
  mutate(weekday = weekday + 1) %>% 
  # transformar a variavel de feriado para texto
  mutate(holiday = as.character(holiday)) %>% 
  # mudar os valores de algumas variaveis
  mutate(
    # substituir o codigo do ano  pelo ano real
    year = lubridate::year(dteday),
    # adicionar um leading zero no mês
    month = str_pad(month, width = 2, side = "left", pad = "0"),
    # converter weathersit para variavel do tipo factor
    weathersit = factor(weathersit,
                        levels = 1:4,
                        labels = c("muito bom", "bom", "ruim", "muito ruim")),
    # converter dia da semana para variavel do tipo factor
    weekday = factor(weekday, 
                     levels = 1:7,
                     labels = c("Dom", "Seg", "Ter", "Qua", "Qui", "Sex", "Sab")),
    # fazer o mesmo para estacao
    estacao = factor(estacao, 
                     levels = 1:4,
                     labels = c("Primavera", "Verao", "Outono", "Inverno")),
    # converter colunas numericas para escala normal (não-normalizada)
    temp = temp * 41,
    atemp = atemp * 50,
    hum = hum * 100,
    windspeed = windspeed * 67
  )

```


Estamos interessados em entender o que influencia a demanda de bicicletas alugadas por dia.

## Análise exploratória


O primeiro passo para entendermos nossa variável de estudo é criar um gráfico da série:

```{r, fig.width=9}
df_transf %>% 
  ggplot(aes(x = dteday, y = total)) +
  geom_line() +
  # adicionar curva de tendencia
  geom_smooth(se = FALSE) +
  theme_bw() +
  # quebrar eixo x em 1 mes
  scale_x_date(date_breaks = "1 month",
               date_labels = "%m/%Y",
               minor_breaks = NULL) +
  # inverter eixos
  theme(axis.text.x = element_text(angle = 90))
```

Apenas com o gráfico acima, podemos aprender uma série de insights interessantes:  

* Parece haver múltiplas sazonalidades que afetam a demanda por bicicletas alugadas: dia da semana, mês, ano e estação do ano.  
* Não existe um componente de tendência linear, pois as altas e quedas são mais em função das sazonalidades descritas acima.

<div class="alert alert-danger"
<strong>Exercícios:</strong>
<br>
- Como você faria para representar a estação do ano no gráfico acima? Teste duas abordagens: acrescente linhas verticas tracejadas marcando a transição das estações ou pinte a linha (usando `aes`) de acordo com a estação.  
- Explore com mais detalhes a distribuição da variável `total` em função de:
<br>
  - Dia da semana & Feriado  
  - Dia da semana & Condição do tempo  
  - Mês & Estação do ano  
  - Mês & Ano
</div>


## Correlação

Correlação é um indicador estatístico que mede o nível de dependência linear entre duas variáveis. Está definida no intervalo $[-1, +1]$. Se a correlação é negativa, indica que as variáveis são inversamente proporcinais: quando uma aumenta, a outra diminui. Se é positiva, indica que as variáveis são diretamente proporcionais.

Medir a correlação no R é muito simples:

```{r}
# Usando a função cor
cor(df_transf$total, df_transf$temp)
cor(df_transf$temp, df_transf$atemp)
```

Como poderia se esperar, as variáveis `temp` e `atemp` são praticamente a mesma, apresentando uma correlação quase igual a 1. Isso, em regressão, é um problema chamado multicolinearidade. Por isso, é necessário remover uma delas:

```{r}
df_transf <- df_transf %>% 
  select(-atemp)
```


No entanto, é possível analisar todos os pares possíveis entre as variáveis de uma matriz numérica:

```{r}
df_transf %>% 
  select_if(is.numeric) %>% 
  select(-year) %>% 
  cor()
  
```

Um incremento ainda melhor é usar o pacote `GGally` para plotar uma matriz de correlação:

```{r}
df_transf %>% 
  select_if(is.numeric) %>% 
  select(-c(year, casual, registered)) %>% 
  GGally::ggpairs(progress = FALSE)

```


Percebe-se pela matriz de correlação (e principalmente pelo gráfico) que talvez só valeria a pena usar como variáveis explanatórias do nosso objeto de estudo a temperatura do dia.


## Modelagem por regressão simples

No R, é bem simples ajustar um modelo de regressão. Usando a variável `temp` como explanatória e `total` como resposta, um modelo é construído da seguinte maneira:

```{r}
modelo.simples <- lm(total ~ temp, data = df_transf)
summary(modelo.simples)

```

Com o modelo criado, é possível descrever a relação entre `consumo` e `n_carteiras` matematicamente por meio da seguinte equação:  

$total = 1214.642 + 161.969 \times temperatura$

Vamos deixar para analisar os diagnósticos da regressão no próximo item:

## Regressão multivariada

Suponha também que você deseja incorporar as outras variáveis que detectamos que são importantes para modelar a variável da quantidade de bikes alugadas:

```{r, fig.height=5}
# sintaxe para incluir todas as variaveis como regressoras menos uma (dteday)
modelo.multiplo <- lm(total ~ . - dteday - casual - registered, data = df_transf)
summary(modelo.multiplo)


```

Valores altos de impostos aparentam estar associados com valores baixos de consumo.

Para adicionar uma nova variável ao modelo, fazemos:

```{r}
# Usando o pacote broom para formatar o output dos modelos de regressao
# concatenando os dois modelos em um dataframe so

# metricas dos regressores
modelo.simples %>% tidy()
modelo.multiplo %>% tidy()

# metricas do modelo
modelo.simples %>% glance()
modelo.multiplo %>% glance()

```

Agora vamos à análise dos indicadores da regressão:

### Hipótese nula da regressão

A presença de um valor-p indica que existe uma hipótese nula sendo testada. Na regressão linear, a hipótese nula é a de que os coeficientes das variáveis explanatórias são iguais a zero. A hipótese alternativa é a de que os coeficientes não são iguais a zero, ou seja, existe uma relação matemático entre as variáveis do modelo.

### valor-p

Nós podemos considerar um modelo linear estatisticamente significante apenas se os valores-p, tanto dos coeficientes como do modelo, são menores que um nível de significância pré-determinado, que idealmente é 0,05.


### R-quadrado e R-quadrado ajustado

R-quadrado é a proporção da variação da variável resposta que é explicada pelo modelo. Quanto maior, melhor o modelo, supostamente.

Se continuarmos adicionando variáveis ao modelo de regressão, o R-quadrado apenas tende a crescer, intuitivamente. Isso acontecerá mesmo que a variável explanatória adicionada não seja significante. Para evitar esse problema que tornaria a comparação entre modelos praticamente inviável, o R-quadrado ajustado "penaliza" o valor do R-quadrado pelo número de variáveis adicionadas. Semelhantemente ao R-quadrado, quanto maior, melhor.


### Análise dos resíduos

Um indicador visual da qualidade de um modelo é a distribuição dos modelos: um bom modelo apresentará resídos que seguem uma distribuição normal com média 0.

Um modelo de regressão pressupõe que seus resíduos (subtração entre o valor real e o ajustado) seguem uma distribuição normal e não possuem nenhum tipo de relação matemática com os regressores do modelo (ou mesmo com variáveis independentes não usadas no modelo).


```{r}
forecast::checkresiduals(modelo.multiplo)
```

## Regressão como modelo preditivo {#modelo-preditivo}

Um dos objetivos da regressão, além de descrever matematicamente a relação entre duas ou mais variáveis, é prever o valor da variável dependente baseado em novos valores da variável independente. Não é possível afirmar que um modelo apresentará um bom desempenho preditivo analisando apenas as métricas da regressão do tópico anterior. É necessário testar o modelo em dados que ele nunca viu.

A prática comum em Data Science é de separar o conjunto de dados que se tem em mãos em dois conjuntos: o de treino, que será usado para construir o modelo, e o de teste, que será usado como input do modelo para avaliar sua acurácia.

Após obter as previsões, deve-se usar uma ou mais métricas de erro (ver capítulo posterior) para avaliar a precisão do modelo.

```{r}

indice_teste <- tail(1:nrow(df_transf), 60)
treino <- df_transf[-indice_teste, ]  # model training data
teste  <- df_transf[indice_teste, ]   # test data

# construindo os dois modelos, mantendo o teste de fora
modelo.simples <- lm(total ~ temp, data = treino)
modelo.multiplo <- lm(total ~ . - dteday - casual - registered, data = treino)

# calcular previsao baseado no dataframe de teste
prev.simples <- predict(modelo.simples, teste)
prev.mult <- predict(modelo.multiplo, teste)
# uma das metricas é correlação entre previsto e real:
real <- teste$total

# outra metrica é o MAPE
ape <- function(yreal, yprev) {
  abs((yreal - yprev)/yreal)
}

mean(ape(yreal = real, yprev = prev.simples))
mean(ape(yreal = real, yprev = prev.mult))

```
Os dois modelos apresentam resultados semelhantes de erro. Portanto, pelo menos para este teste, não houve um aumento significativo de acurácia no modelo ao incorporar a variável `imposto` como explanatória.



## Referências

* [Pressupostos sobre regressão linear](http://r-statistics.co/Assumptions-of-Linear-Regression.html);  
* [Datasets](https://archive.ics.uci.edu/ml/datasets.html?area=&att=&format=&numAtt=&numIns=&sort=nameUp&task=reg&type=&view=table) para você praticar regressão linear.

<div class="alert alert-danger"
<strong>Exercícios:</strong>
<br>
- Importe [este dataset de consumo de petróleo](https://github.com/sillasgonzaga/curso_series_temporais/blob/master/data/petrol_consumption.csv) para o R.  
- Qual a variável resposta?     
- Quais variáveis explanatórias incluir no modelo?  
- Quais gráficos para analisar as variáveis e os modelos?  
</div>


![](http://i.imgur.com/lBCBhhP.jpg)



